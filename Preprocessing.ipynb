{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent directory\n",
    "parent_dir = '/home/Top 10/Teams'\n",
    "main_folders = [os.path.join(parent_dir, dir) for dir in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, dir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No empty folders\n"
     ]
    }
   ],
   "source": [
    "#remove folders with no csv files\n",
    "sub_dirs = []\n",
    "\n",
    "for folder in main_folders:    \n",
    "    subfolder_dirs = [os.path.join(folder, dir) for dir in os.listdir(folder) if os.path.isdir(os.path.join(folder, dir))]\n",
    "    \n",
    "    csvlist = []\n",
    "    for dir in subfolder_dirs:\n",
    "        csvfiles = [os.path.join(dir, csv) for csv in os.listdir(dir) if os.path.isfile(os.path.join(dir, csv)) and csv.endswith('.csv')]\n",
    "        for file in csvfiles:\n",
    "            csvlist.append(file)\n",
    "            \n",
    "    if len(csvlist)!=0:\n",
    "        sub_dirs.append(folder)\n",
    "    else:\n",
    "        print('No csv files in - ',folder)\n",
    "    \n",
    "if sub_dirs:\n",
    "    print(\"No empty folders\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team names\n",
    "team_name = []\n",
    "for i in sub_dirs:\n",
    "    team_name.append(os.path.basename(os.path.normpath(i)))\n",
    "\n",
    "col_name = team_name.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Manchester City F.C\n",
      "2 - Real Madrid C.F\n",
      "3 - Liverpool F.C\n",
      "4 - Juventus F.C\n",
      "5 - Flamengo\n",
      "6 - Chelsea F.C\n",
      "7 - FC Barcelona\n",
      "8 - Paris Saint-Germain\n",
      "9 - Arsenal F.C\n",
      "10 - Manchester United F.C\n"
     ]
    }
   ],
   "source": [
    "#dataFrame of each team\n",
    "d = {}\n",
    "\n",
    "for name, team in zip(team_name, sub_dirs):\n",
    "    print((team_name.index(name)+1),'-',name)\n",
    "    \n",
    "    subject_dirs = [os.path.join(team, dir) for dir in os.listdir(team) if os.path.isdir(os.path.join(team, dir))]\n",
    "\n",
    "    filelist = []\n",
    "    for dir in subject_dirs:\n",
    "        csv_files = [os.path.join(dir, csv) for csv in os.listdir(dir) if os.path.isfile(os.path.join(dir, csv)) and csv.endswith('.csv')]\n",
    "        for file in csv_files:\n",
    "            filelist.append(file)\n",
    "            \n",
    "    li = []     \n",
    "     \n",
    "    for filename in filelist:\n",
    "        df = pd.read_csv(filename, index_col=None, sep=None, usecols = ['Keyword'],engine='python')\n",
    "        df = df.reindex(columns=[*df.columns.tolist(), *col_name], fill_value=0)\n",
    "        df[name] = 1\n",
    "        li.append(df)  \n",
    "\n",
    "    d[name] = pd.concat(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words\n",
    "replace_set = {'vs', 'football', 'club', 'kit', 'v', 'x', 'fc', 'logo', 'logos', 'kits', 'tv', 'fútbol', '512x512',\n",
    "               '512', 'game', 'games', 'watch', 'live', 'scores', 'score', 'online', 'free', \n",
    "               'streaming', 'stream', 'final', 'apk', 'torrent', 'xbox', 'android', 'transmission',\n",
    "               'transmissoes', '.com', 'award', 'awards', 'week', 'weekspredictions', 'prediction', \n",
    "               'review', 'reference', 'referees', 'referee', 'season', 'shirt', 'shrits', 'bet', 'betting', \n",
    "               'shop', 'year', 'years', 'www', 'www.', 'standings', 'table', 'tabelle', 'highlight', 'highlights',\n",
    "               '0', '3', '4', '5', '6', '7', '8', '9', 'now', 'and', 'la', 'scheudule', 'ticket', 'tickets', \n",
    "               'latest', 'as', 'time', 'broadcasting', 'broadcast', 'full', 'link', 'links', 'must', \n",
    "               'update', 'updates', 'co', '.co', 'uk', '01', '02', '03', '04', '05', '06', '07', '08', '09', \n",
    "               '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25',\n",
    "               '26', '27', '28', '29', '30', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', \n",
    "               '2008', '2009', '20102011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019',\n",
    "               '2k11', '2k12', '2k13', '2k14', '2k15', '2k16', '2k17', '2k18', '2k19', '2k20', '.', '&', '$', \n",
    "               'ha', 'win', 'gole', 'mac1', 'line', 'una', 'que', 'ao', 'card', 'store', 'vivo', 'imagene',\n",
    "               'airport', 'sky', 'al', 'hotel', 'como', 'bu', 'le', 'em', 'dela', 'hd', 'para', 'resumen', \n",
    "               'futbol', 'entrada', 'download', 'draft', 'auto', 'nike', 'pc', 'cup', 'foot', 'result',\n",
    "               'channel', 'ma', 'da', 'meme', 'entre', 'uniform', 'wallpaper', 'list', 'por', 'png', 'pick',\n",
    "               'fichaje', '2k', 'schedule', 'many', 'con', 'comprar', 'canal', 'top', 'restaurant', \n",
    "               'youtube', 'bein', 'stat', 'hockey', 'cricket', 'player', 'escudo', 'price', 'un', 'mas', \n",
    "               'playoff', 'head', 'fan', 'hora', 'foto', 'predictions', 'per', 'bbc', 'date', 'basket', \n",
    "               'izle', 'fox', 'bus', 'mobile', 'today', 'ps', 'ranking', 'flight', 'las', 'one', 'goles', \n",
    "               'pass', 'national', 'soccer', 'di', 'asstirtir', 'resultado', 'imagenes', 'bola', 'star',\n",
    "               'sport', 'ol', 'les', 'best', 'direct', 'gol', 'english', 'last', 'fußball', 'rusia', 'trial', \n",
    "               'stage', 'fixtures', 'trials', 'train', 'ststion', 'booking', 'theme', 'music', 'hat', \n",
    "               'baseball', 'merchandise', 'up', 'coaches', 'coaching', 'fans', 'forum', 'profile', 'home',\n",
    "               'the', 'in', 'community', 'badges', 't20', 'pinterest', 'shirts', 'shorts', 'openning',\n",
    "               'voucher', 'codes', 'order', 'of', 'play', 'clothing', 'drivers', 'garage', 'jacket', \n",
    "               'point', 'match', 'replay', 'ticketmaster', 'box', 'preseason', 'f.c', 'team', 'nationals', \n",
    "               'a.f.c', 'cf', 'c.f'}\n",
    "\n",
    "#nltk stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html-tags\n",
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any punctuation or special characters\n",
    "def cleanPunc(sentence): \n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove html-tags, and non-alphabetic characters \n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove white space  \n",
    "def whitespace(sentence):\n",
    "    space_removed = \" \".join(sentence.split())\n",
    "    return space_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(name):\n",
    "    d[name]['Keyword'] = d[name]['Keyword'].apply(cleanHtml)\n",
    "    d[name]['Keyword'] = d[name]['Keyword'].apply(cleanPunc)\n",
    "    d[name]['Keyword'] = d[name]['Keyword'].apply(keepAlpha)    \n",
    "    d[name]['Keyword'] = d[name]['Keyword'].str.split(' ').apply(lambda x: ' '.join(k for k in x if k not in replace_set))\n",
    "    d[name]['Keyword'] = d[name]['Keyword'].str.split(' ').apply(lambda x: ' '.join(k for k in x if k not in stop_words))\n",
    "    d[name]['Keyword'] = d[name]['Keyword'].apply(whitespace)\n",
    "    d[name].drop_duplicates(subset ='Keyword', keep = 'first', inplace = True) \n",
    "    d[name] = d[name].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Manchester City F.C\n",
      "2 - Real Madrid C.F\n",
      "3 - Liverpool F.C\n",
      "4 - Juventus F.C\n",
      "5 - Flamengo\n",
      "6 - Chelsea F.C\n",
      "7 - FC Barcelona\n",
      "8 - Paris Saint-Germain\n",
      "9 - Arsenal F.C\n",
      "10 - Manchester United F.C\n"
     ]
    }
   ],
   "source": [
    "#cleaning       \n",
    "for col in col_name:\n",
    "    print((col_name.index(col)+1),'-',col)\n",
    "    clean(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining dataFrames\n",
    "data = pd.concat(d.values())\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregating\n",
    "all_col= data.columns\n",
    "all_team_name = all_col[1::]\n",
    "dictofteam = { i : 'sum' for i in all_team_name}\n",
    "\n",
    "data = data.groupby('Keyword').agg(dictofteam).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data saving\n",
    "data.to_csv('/home/Top 10/data.csv', sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
